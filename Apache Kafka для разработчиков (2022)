1 урок. Введение

План
1 день
-устройство kafka
-основы взаимодействия
-продвинутое взаимодействие
2 день
-алгоритмы с использованием kafka
-критическая бизнес логика на kafka
3 день
-kafka как синхронизатор(аналог mutex, monitor, semaphore в java)
-kafka как БД

-Зачем создали kafka?
Для закрытия потребности в обработке больших потоков данных между различными частями платформы, приложения, сервисов.
-Как используют kafka?
Используется, когда речь заходит про обработку больших объемов данных в реальном времени, а также производительности и сохранности данных.
примеры использования:
брокер сообщений для межсервисного взаимодействия
обработка событий от пользователей
система очередей
журналирование
сбор метрик
commit log(для транзакций)
центральное хранилище информации

2.1 урок. Термины в kafka мире.
термины:
-кластер - набор инстансов kafka(kafka-broker) + БД(zookeeper). Это некий черный ящик к кторому обращается пользователь.
к кластерам могут подключаться сервисы. к сервисам могут подключаться клиенты.
-нода - один инстанс kafka(kafka-broker). минимальная логическая единица.
-датацентр - набор хардвар-серверов. кластер kafka может быть(но не обязательно) развернут между несколькими датацентрами.
-producer - система, которая пишет сообщения(record) в kafka. свой сервис. пишет сообщения в topic кластера kafka.
-consumer - система, которая потребляет сообщения из kafka. свой сервис.
сложно уследить за всеми consumer'ами. в случае изменения формата сообщения(record), которое пишет producer, может быть конфуз с тем, что consumer'ы могут будут не готовы или могут не знать, что нужно изменить получаемый формат.
"Видишь consumer? Нет. А он есть!"
-topic - логическая единица внутри kafka. используется для принятия-передачи сообщений(record) между producer-consumer.
в каждый topic должны записываться собщения с кокретным атомарным смыслом(если topic называется order, то в него можно писать только "заказы", но никак не "дни недели" и др.)
данные должны делится по topic'ам, для их логического распределения в системе
один кластер kafka может включать в себя большое кол-во topic'ов
-record - сообщение с определенным форматом. Записывается в topic producer'ом. Читается из topic'а consumer'ом.
структура сообщения: key-value-timestamp(key - способ управления партициями; value - по сути это payload с произвольной последовательностью байтов; timestamp - временная метка успешной доставки и сохранения сообщения в ноде kafka)
-партиция - составляющая часть topic'а. сообщения в topic'е распределяются в случайном порядке по партициям и сохраняются в них

CAP Theorem - теорема распределенных систем:
консистентность<->доступность<->сетевые отказы - реализуемо только 2 из 3 пунктов
консистентность<->доступность - это Oracle SQL
доступность<->сетевые отказы - это CouchDB
консистентность<->сетевые отказы - это MongoDB
консистентность - это ожидаемое состояние данных в хранилище данных
доступность - это состояние системы при котором она может что-то ответить в случае обращения к ней
сетевые отказы - это проблемы аппаратного и программного обеспечения, которые непосредственно связаны с сетью

Zookeeper - обслуживающая система kafka. по сути БД.
сосредоточена на том, чтобы обеспечить максимальную скорость чтения и не очень максимальную скорость записи.
может масштабироваться. обеспечивает отказоустойчивость.
kafka хранит в ней свои конфигурационные настройки.

3.Архитектура kafka
3.1.Партиционирование(шардирование)
-каждый producer пишет во все(?) брокеры kafka
-topic существует только на логическом уровне представления. на физическом уровне topic'ов не существует
-topic по сути является набором партиций
    оптимальное кол-во партиций для одного consumer'а - 4шт.
kafka распределяет партиции самостоятельно, и не всегда это делает оптимально:
к примеру при создании одного топика кафка, может разместить все пратиции на одном узле(а это не оптимально)
только если создать большое кол-во партиций, то они более или менне равномерно распределеяться по нодам
но слишком много партиций - это ресурсозатратно
чем больше партиций тем большая нагрузка может быть выдержана
-кафка отказоустойчива за счет репликации
виды реплик: leader-folower
leader - основная реплика для записи-чтения
folower - реплики для бэкапа основной реплики
    оптимальное кол-во реплик - 3шт.
3.2 Концепция указателей (смещений), буферная передача и задержка
-kafka может сама менять leader-ноду в случае сбоя в брокерах
при смене leader-ноды могут быть потеряны сообщения, в случае если новая leader-нода содержит не актуальные сообщения по сравнению с предыдущей leader-ноды
новая leder-нода может быть неактуальной в силу задержки репликации
это проблема CAP теоремы
решение:
через установку свойств:
настраивается для каждого топика отдельно
min.insync.replicas=1 - задает минимальный порог для количества реплик в списке ISR(insync replicas)
acks=all - количество подтверждений, которые продюсер должен получить от брокера-лидера, прежде чем считать запрос завершенным
    доступные значения:
        0 - продюсер послал сообщение и не ожидает подтверждения записи, 
        1 - запись только на лидер ноду т.е. продюсер ожидает подтверждение, когда на лидер ноду будет записано сообщение
        all(-1) - продюсер ожидает подтверждения, когда сообщение будет реплицировано на все insync ноды(кол-во insync нод задается через свойство min.insync.replicas)
    если продюсер ожидал, но не получил подтверждения о записи сообщения на ноду(или несколько нод, то он может повторить отправку сообщения)
unclean.leader.election.enable=false - указывает, могут ли брокеры в списке ISR(insync replicas), которые не догнали лидера (т.е. "нечистые"), сами стать лидерами
kafka разделяет реплики на insync - синхронизированы с лидер нодой и not-insync - не синхронизированы с лидер нодой
есть опасность, что сообщения все-равно могут быть потеряны, если лидер нода будет изменена на не insync ноду, но от защищает свойство unclean.leader.election.enable=false
чтение сообщений из брокера невозможно пока сообщение не будет записано во все insync реплики или пока реплика(и) не выйдет из состояния insync(это примерно 10сек., настраивается через свойство)
    т.е. если чтение из kafka тормозит на 10сек., то вероятно, что insync ноды тормозят и возможно стоит уменьшить значение свойства изменения статуса репликации на insync
-kafka хранит записи в формате лога, запись нового сообщения производится только в конец лога
kafka - это распределенный лог
-формат данных в kafka:
    offset или номер записи(инкрементируемый) - это уникальный адрес сообщения, в рамках одной партиции(партиция состоит из имени топика и номера партиции)
    createdTime или время записи - время когда сообщение было добавлено
    key или ключ записи(опционально) - объект к которому относится это сообщение, если множество сообщений записано с одинкаковы ключом, то они будут записаны в одну партицию и прочитано в том же порядке, как записывались
    payload или данные записи - само сообщение
-данные пишутся в kafka сегментами(batch'ами)
продюсер перед отправкой сообщения формирует их в batch'и и посылает в kafka целым batch'ом
-удаление сообщений из kafka
kafka удаляет данные целыми файлами(с сообщениями)
при достижении определенного размера или кол-ва сообщений или достижении определенного времени kafka может удалить этот файл, есть и др.настройки удаления
но можно отключить удаление файлов
-Zero-copy - kafka может отправлять данные в сеть минуя ЦП(центральный процессор)
данные пишутся в память и забираются сетевой картой из памяти без участия ЦП
это очень производительное решение
